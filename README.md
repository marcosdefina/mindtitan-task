# Sample task starter

Here you'll find a skeleton project for a simple Flask API.
To include private configuration, rename `config/private_RENAME_THIS.py` to `private.py`. Keep secret credentials there.

Build the docker image:  
`sudo docker build -t sampletask .`

Run the docker image:
`sudo docker run --net="host" sampletask`

Run as developer:
`python main.py`

The "Hello world!" can now be observed on   localhost at port 5000. 

### Data architecture
 - I tried to use everything as dictionary. Where the user_id is the key and the request_counter is the value, the nearst of json in python I could imagine.
 - the landing page is redirect to the form.html template, where there is an id input, which of course would be auto generated by api and would be requested in the user login, but in this case I tryed to be simplier. The question is not being used, it just disapier and if the user_id already exists, the value in the dictionary will increment by 1, if not, will be created a new element in the dictionary with 1 in its value.
  - When you click submit, you'll be redirected to a page where shows a table with your key and you message, but this is just garbage from when I was learning flask, like, 3 hours ago. I just forgot to take it out. If you want to see the things changing, try the '/database' end-point.

### Explanations

 - I was trying to deal with this organization with flask and things I didn't know about python, like how to use C-pthread libraries like in python, or even if I had to do it.

 - As I guessed, I had to do is to simulate the backbone of the system. And I kind of did it.

 - I would just need more time to make it works properly.

### Plans
 - I will learn how to use and use python libraries to send any request to a free core in the processors. I heard about Hadoop in a database event one time, but I don't know if its fit, just has to seek a little bit more.
 - I have read a little bit of AWS lambda functions - Serverless backend, as I understood, maybe would help to minimize the costs of our hypothetical company, and could be as scalable as we want if we just using the horizontal scalability, sending requests to be requested by free cores. Supposing infinite cores at AWS we could have only the ping and the processing as response time, avoiding the problem with overload in the old approach.
